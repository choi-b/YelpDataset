{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM with Other Datasets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dGzWgxUdpKQ0",
        "colab_type": "code",
        "outputId": "cfd87827-5147-40ea-d1f3-9a0884bf20fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (required if running on Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4mEpLX3Po-G-",
        "colab_type": "code",
        "outputId": "7228196a-1b0c-474c-9660-aa5d3987a046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "# Install required modules\n",
        "# !pip install '/content/drive/Team Drives/Deep Learning Team Drive/yelp_dataset_challenge-master/yelp_util'\n",
        "!pip install Cython\n",
        "# !pip install word2vec\n",
        "!pip install gensim\n",
        "!pip install unidecode\n",
        "!pip install textblob\n",
        "!pip install wordcloud\n",
        "\n",
        "\n",
        "# Import required modules\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# import yelp_util\n",
        "# from yelp_util import downloader as dl\n",
        "import os\n",
        "from scipy import misc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import random\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.62)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.62 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.62)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.0.23)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.2)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.11.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7hlPtZ4Yuyp",
        "colab_type": "code",
        "outputId": "97d6ed53-cf52-4cbf-f298-d7f7a80517fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "##Chinese REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewChin = pd.read_pickle(os.path.join(download_path, 'chinese_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=12345).permutation(reviewChin.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewChin = reviewChin.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewChin = reviewChin.loc[:, ['stars','text']]\n",
        "reviewChin = reviewChin[reviewChin.stars != 3]\n",
        "reviewChin.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewChin['sentiment']=['pos' if (x>3) else 'neg' for x in reviewChin['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewChin['text']= [x.lower() for x in reviewChin['text']]\n",
        "reviewChin['text'] = reviewChin['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "reviewChin.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>my wife and i are big fans of the pei wei chai...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>great delivery and even better dinein experien...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>quality was excellent food was fresh and reaso...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>service was mediocre  asked for the dishes to ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>really enjoyed lunch here greeted by beautiful...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   stars                                               text sentiment\n",
              "0      2  my wife and i are big fans of the pei wei chai...       neg\n",
              "1      4  great delivery and even better dinein experien...       pos\n",
              "3      5  quality was excellent food was fresh and reaso...       pos\n",
              "4      2  service was mediocre  asked for the dishes to ...       neg\n",
              "5      5  really enjoyed lunch here greeted by beautiful...       pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "hBm1c6ynZGrN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, CuDNNLSTM, Bidirectional\n",
        "from keras.metrics import categorical_accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "tokenizer = Tokenizer(num_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',                                  \n",
        "                      lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(reviewChin['text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SAHyRbJZXZg",
        "colab_type": "code",
        "outputId": "fb0400f0-4bff-4aaf-e402-7caef29e6f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "X = tokenizer.texts_to_sequences(reviewChin['text'].values)\n",
        "X = pad_sequences(X)\n",
        "Y = pd.get_dummies(reviewChin['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34413, 870) (34413, 2)\n",
            "(8604, 870) (8604, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uuWkvS7RpB-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb7833e9-03be-4107-9357-ce6cd6b0f281"
      },
      "cell_type": "code",
      "source": [
        "##Italian REVIEWS##\n",
        "\n",
        "# Download and unpickle data\n",
        "\n",
        "reviewItaly = pd.read_pickle(os.path.join(download_path, 'italian_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=12345).permutation(reviewItaly.shape[0])\n",
        "\n",
        "# Reset index so it stays in the new order\n",
        "reviewItaly = reviewItaly.iloc[shuffidx].reset_index(drop=True)\n",
        "\n",
        "#preprocess\n",
        "reviewItaly = reviewItaly.loc[:, ['stars','text']]\n",
        "reviewItaly = reviewItaly[reviewItaly.stars != 3]\n",
        "reviewItaly.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewItaly['sentiment']=['pos' if (x>3) else 'neg' for x in reviewItaly['stars']] #add the sentiment column\n",
        "\n",
        "#remove punctuations\n",
        "import re\n",
        "reviewItaly['text']= [x.lower() for x in reviewItaly['text']]\n",
        "reviewItaly['text'] = reviewItaly['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "#tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',                                  \n",
        "                      lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(reviewItaly['text'].values)\n",
        "XI = tokenizer.texts_to_sequences(reviewItaly['text'].values)\n",
        "XI = pad_sequences(XI)\n",
        "\n",
        "YI = pd.get_dummies(reviewItaly['sentiment']).values\n",
        "X_trainI, X_testI, Y_trainI, Y_testI = train_test_split(XI,YI, test_size = 0.2, random_state = 22)\n",
        "print(X_trainI.shape,Y_trainI.shape)\n",
        "print(X_testI.shape,Y_testI.shape)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57500, 932) (57500, 2)\n",
            "(14375, 932) (14375, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dfG6UGZgpCCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65fbdbbc-a762-4cd3-aec9-3458c4217730"
      },
      "cell_type": "code",
      "source": [
        "##MEXICAN RESTAURANT REVIEWS##\n",
        "\n",
        "# Download and unpickle data\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "\n",
        "reviewMex = pd.read_pickle(os.path.join(download_path, 'mexican_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewMex.shape[0])\n",
        "\n",
        "# Reset index so it stays in the new order\n",
        "reviewMex = reviewMex.iloc[shuffidx].reset_index(drop=True)\n",
        "\n",
        "#preprocess\n",
        "reviewMex = reviewMex.loc[:, ['stars','text']]\n",
        "reviewMex = reviewMex[reviewMex.stars != 3]\n",
        "reviewMex.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewMex['sentiment']=['pos' if (x>3) else 'neg' for x in reviewMex['stars']] #add the sentiment column\n",
        "\n",
        "#remove punctuations\n",
        "import re\n",
        "reviewMex['text']= [x.lower() for x in reviewMex['text']]\n",
        "reviewMex['text'] = reviewMex['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "#tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',                                  \n",
        "                      lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(reviewMex['text'].values)\n",
        "XM = tokenizer.texts_to_sequences(reviewMex['text'].values)\n",
        "XM = pad_sequences(XM)\n",
        "\n",
        "YI = pd.get_dummies(reviewMex['sentiment']).values\n",
        "X_trainM, X_testM, Y_trainM, Y_testM = train_test_split(XM,YM, test_size = 0.2, random_state = 42)\n",
        "print(X_trainM.shape,Y_trainM.shape)\n",
        "print(X_testM.shape,Y_testM.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64582, 913) (64582, 2)\n",
            "(16146, 913) (16146, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EbwL6vALpCGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b1a508c9-c152-4de1-c51d-2db263b04441"
      },
      "cell_type": "code",
      "source": [
        "##HAIR SALON REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewHair = pd.read_pickle(os.path.join(download_path, 'salon_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=1234).permutation(reviewHair.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewHair = reviewHair.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewHair = reviewHair.loc[:, ['stars','text']]\n",
        "reviewHair = reviewHair[reviewHair.stars != 3]\n",
        "reviewHair.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewHair['sentiment']=['pos' if (x>3) else 'neg' for x in reviewHair['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewHair['text']= [x.lower() for x in reviewHair['text']]\n",
        "reviewHair['text'] = reviewHair['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "tokenizer.fit_on_texts(reviewHair['text'].values)\n",
        "XH = tokenizer.texts_to_sequences(reviewHair['text'].values)\n",
        "XH = pad_sequences(XH)\n",
        "YH = pd.get_dummies(reviewHair['sentiment']).values\n",
        "X_trainH, X_testH, Y_trainH, Y_testH = train_test_split(XH,YH, test_size = 0.2, random_state = 42)\n",
        "print(X_trainH.shape,Y_trainH.shape)\n",
        "print(X_testH.shape,Y_testH.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13218, 935) (13218, 2)\n",
            "(3305, 935) (3305, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f0joYmvepCLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "341f5d82-af4b-4566-efb5-2ece600d8561"
      },
      "cell_type": "code",
      "source": [
        "##Home and Garden REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewHome = pd.read_pickle(os.path.join(download_path, 'homegarden_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=1234).permutation(reviewHome.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewHome = reviewHome.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewHome = reviewHome.loc[:, ['stars','text']]\n",
        "reviewHome = reviewHome[reviewHome.stars != 3]\n",
        "reviewHome.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewHome['sentiment']=['pos' if (x>3) else 'neg' for x in reviewHome['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewHome['text']= [x.lower() for x in reviewHome['text']]\n",
        "reviewHome['text'] = reviewHome['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "tokenizer.fit_on_texts(reviewHome['text'].values)\n",
        "XHG = tokenizer.texts_to_sequences(reviewHome['text'].values)\n",
        "XHG = pad_sequences(XHG)\n",
        "YHG = pd.get_dummies(reviewHome['sentiment']).values\n",
        "X_trainHG, X_testHG, Y_trainHG, Y_testHG = train_test_split(XHG,YHG, test_size = 0.2, random_state = 12)\n",
        "print(X_trainHG.shape,Y_trainHG.shape)\n",
        "print(X_testHG.shape,Y_testHG.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7288, 909) (7288, 2)\n",
            "(1823, 909) (1823, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YiXBl3dtpCQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a7a25ab-9841-433b-a34e-99020f00ef06"
      },
      "cell_type": "code",
      "source": [
        "##Band and Credit Union REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewBCU = pd.read_pickle(os.path.join(download_path, 'bankandcu_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=1234).permutation(reviewBCU.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewBCU = reviewBCU.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewBCU = reviewBCU.loc[:, ['stars','text']]\n",
        "reviewBCU = reviewBCU[reviewBCU.stars != 3]\n",
        "reviewBCU.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewBCU['sentiment']=['pos' if (x>3) else 'neg' for x in reviewBCU['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewBCU['text']= [x.lower() for x in reviewBCU['text']]\n",
        "reviewBCU['text'] = reviewBCU['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "tokenizer.fit_on_texts(reviewBCU['text'].values)\n",
        "XBCU = tokenizer.texts_to_sequences(reviewBCU['text'].values)\n",
        "XBCU = pad_sequences(XBCU)\n",
        "YBCU = pd.get_dummies(reviewBCU['sentiment']).values\n",
        "X_trainBCU, X_testBCU, Y_trainBCU, Y_testBCU = train_test_split(XBCU,YBCU, test_size = 0.2, random_state = 12)\n",
        "print(X_trainBCU.shape,Y_trainBCU.shape)\n",
        "print(X_testBCU.shape,Y_testBCU.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1071, 846) (1071, 2)\n",
            "(268, 846) (268, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O1b4mGbyZSLA",
        "colab_type": "code",
        "outputId": "8f1757eb-463c-4d75-dad8-1b0541d4f055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "###GENERAL LSTM###\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 200\n",
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(2000, embed_dim,input_length = XI.shape[1]))\n",
        "model.add(Embedding(2000, embed_dim))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "#model.add(CuDNNLSTM(lstm_out, return_sequences=False, input_shape=(932, 128)))\n",
        "model.add(CuDNNLSTM(lstm_out, return_sequences=False))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 200)               264000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 520,402\n",
            "Trainable params: 520,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8pjMDQhY2cr",
        "colab_type": "code",
        "outputId": "e4940063-4813-4018-da81-032890f05c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit model (train on Chinese)\n",
        "model.fit(X, Y, validation_split=0.1, epochs=2, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38715 samples, validate on 4302 samples\n",
            "Epoch 1/2\n",
            " - 209s - loss: 0.1276 - acc: 0.9505 - val_loss: 0.1466 - val_acc: 0.9449\n",
            "Epoch 2/2\n",
            " - 209s - loss: 0.1069 - acc: 0.9586 - val_loss: 0.1473 - val_acc: 0.9386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76211d81d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "A-H9MRlqY2gr",
        "colab_type": "code",
        "outputId": "9d653d8b-c6dc-458e-a60e-6ab65526823b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Chinese restaurants\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.16\n",
            "Validation Accuracy: 0.9378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ircLF5C2kI14",
        "colab_type": "code",
        "outputId": "6b38b184-3c63-4f86-a4e4-f9281399236d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Italy set\n",
        "score,acc = model.evaluate(X_testI, Y_testI, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.92\n",
            "Validation Accuracy: 0.6216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNHEL8ltk2Mc",
        "colab_type": "code",
        "outputId": "d02bce7b-2492-4eb9-fee6-ec0c36331924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Mex set\n",
        "score,acc = model.evaluate(X_testM, Y_testM, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.06\n",
            "Validation Accuracy: 0.5741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uE6SlDKHlu4P",
        "colab_type": "code",
        "outputId": "96ec56c3-84b1-49e8-e6dc-cec44792ac3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Hair Salon\n",
        "score,acc = model.evaluate(X_testH, Y_testH, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.88\n",
            "Validation Accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bkLDrG75l41M",
        "colab_type": "code",
        "outputId": "05c33957-f643-477c-8178-ef6ff7233384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Home Garden\n",
        "score,acc = model.evaluate(X_testHG, Y_testHG, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.04\n",
            "Validation Accuracy: 0.6248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d3on6b7FmVNH",
        "colab_type": "code",
        "outputId": "21248d3c-d60d-4c11-9b10-39208a0db244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the BCU\n",
        "score,acc = model.evaluate(X_testBCU, Y_testBCU, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.68\n",
            "Validation Accuracy: 0.4142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7U2T7HgJnM5l",
        "colab_type": "code",
        "outputId": "5d1368f9-944e-40a5-b813-9f89a819c88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "### Try Bidirectional LSTM ###\n",
        "### The following sections ###\n",
        "### were exectued with the following hyper parameters ###\n",
        "\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 200\n",
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(2000, embed_dim))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_out, return_sequences=True)))\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_out)))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 400)         528000    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 400)               963200    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 802       \n",
            "=================================================================\n",
            "Total params: 1,748,002\n",
            "Trainable params: 1,748,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkhXBAKJoWPX",
        "colab_type": "code",
        "outputId": "00743e86-4cc3-44ba-96db-960765411d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit model (train on Chinese)\n",
        "model.fit(X, Y, validation_split=0.1, epochs=2, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38715 samples, validate on 4302 samples\n",
            "Epoch 1/2\n",
            " - 855s - loss: 0.3657 - acc: 0.8328 - val_loss: 0.5115 - val_acc: 0.7053\n",
            "Epoch 2/2\n",
            " - 855s - loss: 0.2680 - acc: 0.8862 - val_loss: 0.1614 - val_acc: 0.9358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76215e9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "uh7MFQTQoWbm",
        "colab_type": "code",
        "outputId": "d7a7e85d-3a44-4ae1-b943-29d61ed55f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Chinese restaurants\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.15\n",
            "Validation Accuracy: 0.9432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iHSjKmWwoWh1",
        "colab_type": "code",
        "outputId": "55059962-34fe-40b0-9a0b-10c0747a3d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Italy set\n",
        "score,acc = model.evaluate(X_testI, Y_testI, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.93\n",
            "Validation Accuracy: 0.6769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qzfLlcLUoiF_",
        "colab_type": "code",
        "outputId": "a43df4c4-52bd-4cec-8581-1c23032c1686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Mex set\n",
        "score,acc = model.evaluate(X_testM, Y_testM, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.10\n",
            "Validation Accuracy: 0.6195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6n9nsu5toiLC",
        "colab_type": "code",
        "outputId": "f35fc13d-d271-4d0b-cf8a-fec9326c3bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Hair Salon\n",
        "score,acc = model.evaluate(X_testH, Y_testH, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.90\n",
            "Validation Accuracy: 0.6859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vA6c5arIoiJV",
        "colab_type": "code",
        "outputId": "692c5f5b-bc5d-4430-e14c-c9c8fa666755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the Home Garden\n",
        "score,acc = model.evaluate(X_testHG, Y_testHG, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.16\n",
            "Validation Accuracy: 0.6336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WX1w_734oWlW",
        "colab_type": "code",
        "outputId": "4fbb159c-a554-4ec7-9a25-6683e90c4e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Test on the BCU\n",
        "score,acc = model.evaluate(X_testBCU, Y_testBCU, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.78\n",
            "Validation Accuracy: 0.4291\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}