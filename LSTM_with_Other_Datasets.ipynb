{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM with Other Datasets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dGzWgxUdpKQ0",
        "colab_type": "code",
        "outputId": "4d48723c-7c15-4004-bc68-fe520da4f18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (required if running on Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4mEpLX3Po-G-",
        "colab_type": "code",
        "outputId": "3924b541-9dc0-4964-bcea-05a9ff4ed393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1227
        }
      },
      "cell_type": "code",
      "source": [
        "# Install required modules\n",
        "# !pip install '/content/drive/Team Drives/Deep Learning Team Drive/yelp_dataset_challenge-master/yelp_util'\n",
        "!pip install Cython\n",
        "# !pip install word2vec\n",
        "!pip install gensim\n",
        "!pip install unidecode\n",
        "!pip install textblob\n",
        "!pip install wordcloud\n",
        "\n",
        "\n",
        "# Import required modules\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# import yelp_util\n",
        "# from yelp_util import downloader as dl\n",
        "import os\n",
        "from scipy import misc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import random\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Cython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/e0/0592be5b851c8013aa253592606ca265862d27444d908e029fd75d563c9c/Cython-0.29.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 12.6MB/s \n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "Successfully installed Cython-0.29.1\n",
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 13.9MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/b9/7df67f1775d240ac8d111211f967fa75ecc9968ae79ffa0594e36345445f/boto3-1.9.62-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.9MB/s \n",
            "\u001b[?25hCollecting botocore<1.13.0,>=1.12.62 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/77/35e82076e3beb506280f94213a258819378115f174e516ce69b3a2336e1c/botocore-1.12.62-py2.py3-none-any.whl (5.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.1MB 7.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.62 botocore-1.12.62 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 11.4MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.0.23\n",
            "Collecting textblob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/7d/ad09a26b63d4ad3f9395840c72c95f2fc9fa2b192094ef14e9e720be56f9/textblob-0.15.2-py2.py3-none-any.whl (636kB)\n",
            "\u001b[K    100% |████████████████████████████████| 645kB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.11.0)\n",
            "Installing collected packages: textblob\n",
            "Successfully installed textblob-0.15.2\n",
            "Collecting wordcloud\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/af/849edf14d573eba9c8082db898ff0d090428d9485371cc4fe21a66717ad2/wordcloud-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
            "\u001b[K    100% |████████████████████████████████| 368kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n",
            "Installing collected packages: wordcloud\n",
            "Successfully installed wordcloud-1.5.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y7hlPtZ4Yuyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8899d947-b3da-4cf7-aa7d-c4dcac796a45"
      },
      "cell_type": "code",
      "source": [
        "##Chinese REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewChin = pd.read_pickle(os.path.join(download_path, 'chinese_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewChin.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewChin = reviewChin.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewChin = reviewChin.loc[:, ['stars','text']]\n",
        "reviewChin = reviewChin[reviewChin.stars != 3]\n",
        "reviewChin.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewChin['sentiment']=['pos' if (x>3) else 'neg' for x in reviewChin['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewChin['text']= [x.lower() for x in reviewChin['text']]\n",
        "reviewChin['text'] = reviewChin['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "reviewChin.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>ive been to this place many times and it has c...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>chicago snowbird turned us on to this restaura...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>the item i wanted when i went thru the drive t...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>no i was not happy with my order its  a new pl...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>tasty is accurate this is chinese for white pe...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   stars                                               text sentiment\n",
              "0      4  ive been to this place many times and it has c...       pos\n",
              "1      4  chicago snowbird turned us on to this restaura...       pos\n",
              "3      2  the item i wanted when i went thru the drive t...       neg\n",
              "4      2  no i was not happy with my order its  a new pl...       neg\n",
              "7      4  tasty is accurate this is chinese for white pe...       pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "hBm1c6ynZGrN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, CuDNNLSTM, Bidirectional\n",
        "from keras.metrics import categorical_accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "tokenizer = Tokenizer(num_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',                                  \n",
        "                      lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(reviewChin['text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SAHyRbJZXZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "175bcd0b-fc81-47e6-fcad-e99c8eb5723a"
      },
      "cell_type": "code",
      "source": [
        "X = tokenizer.texts_to_sequences(reviewChin['text'].values)\n",
        "X = pad_sequences(X)\n",
        "Y = pd.get_dummies(reviewChin['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34413, 858) (34413, 2)\n",
            "(8604, 858) (8604, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uuWkvS7RpB-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Italian REVIEWS##\n",
        "\n",
        "# Download and unpickle data\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "\n",
        "#Chinese Restaurant Reviews\n",
        "#review = pd.read_pickle(os.path.join(download_path, 'chinese_reviews.pickle'))\n",
        "#review = pd.read_pickle(os.path.join(download_path, 'italian_reviews.pickle'))\n",
        "\n",
        "\n",
        "reviewItaly = pd.read_pickle(os.path.join(download_path, 'italian_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewItaly.shape[0])\n",
        "\n",
        "# Reset index so it stays in the new order\n",
        "reviewItaly = reviewItaly.iloc[shuffidx].reset_index(drop=True)\n",
        "\n",
        "#preprocess\n",
        "reviewItaly = reviewItaly.loc[:, ['stars','text']]\n",
        "reviewItaly = reviewItaly[reviewItaly.stars != 3]\n",
        "reviewItaly.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewItaly['sentiment']=['pos' if (x>3) else 'neg' for x in reviewItaly['stars']] #add the sentiment column\n",
        "\n",
        "#remove punctuations\n",
        "import re\n",
        "reviewItaly['text']= [x.lower() for x in reviewItaly['text']]\n",
        "reviewItaly['text'] = reviewItaly['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "#tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',                                  \n",
        "                      lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(reviewItaly['text'].values)\n",
        "XI = tokenizer.texts_to_sequences(reviewItaly['text'].values)\n",
        "XI = pad_sequences(XI)\n",
        "\n",
        "YI = pd.get_dummies(reviewItaly['sentiment']).values\n",
        "X_trainI, X_testI, Y_trainI, Y_testI = train_test_split(XI,YI, test_size = 0.2, random_state = 42)\n",
        "print(X_trainI.shape,Y_trainI.shape)\n",
        "print(X_testI.shape,Y_testI.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfG6UGZgpCCQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##MEXICAN RESTAURANT REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewMex = pd.read_pickle(os.path.join(download_path, 'mexican_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewMex.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewMex = reviewMex.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewMex = reviewMex.loc[:, ['stars','text']]\n",
        "reviewMex = reviewMex[reviewMex.stars != 3]\n",
        "reviewMex.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewMex['sentiment']=['pos' if (x>3) else 'neg' for x in reviewMex['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewMex['text']= [x.lower() for x in reviewMex['text']]\n",
        "reviewMex['text'] = reviewMex['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "tokenizer.fit_on_texts(reviewMex['text'].values)\n",
        "\n",
        "XM = tokenizer.texts_to_sequences(reviewMex['text'].values)\n",
        "XM = pad_sequences(XM)\n",
        "YM = pd.get_dummies(reviewMex['sentiment']).values\n",
        "X_trainM, X_testM, Y_trainM, Y_testM = train_test_split(XM,YM, test_size = 0.2, random_state = 42)\n",
        "print(X_trainM.shape,Y_trainM.shape)\n",
        "print(X_testM.shape,Y_testM.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbwL6vALpCGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##HAIR SALON REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewHair = pd.read_pickle(os.path.join(download_path, 'salon_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewHair.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewHair = reviewHair.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewHair = reviewHair.loc[:, ['stars','text']]\n",
        "reviewHair = reviewHair[reviewHair.stars != 3]\n",
        "reviewHair.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewHair['sentiment']=['pos' if (x>3) else 'neg' for x in reviewHair['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewHair['text']= [x.lower() for x in reviewHair['text']]\n",
        "reviewHair['text'] = reviewHair['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "tokenizer.fit_on_texts(reviewHair['text'].values)\n",
        "XH = tokenizer.texts_to_sequences(reviewHair['text'].values)\n",
        "XH = pad_sequences(XH)\n",
        "YH = pd.get_dummies(reviewHair['sentiment']).values\n",
        "X_trainH, X_testH, Y_trainH, Y_testH = train_test_split(XH,YH, test_size = 0.2, random_state = 42)\n",
        "print(X_trainH.shape,Y_trainH.shape)\n",
        "print(X_testH.shape,Y_testH.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0joYmvepCLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Home and Garden REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewHome = pd.read_pickle(os.path.join(download_path, 'homegarden_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewHome.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewHome = reviewHome.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewHome = reviewHome.loc[:, ['stars','text']]\n",
        "reviewHome = reviewHome[reviewHome.stars != 3]\n",
        "reviewHome.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewHome['sentiment']=['pos' if (x>3) else 'neg' for x in reviewHome['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewHome['text']= [x.lower() for x in reviewHome['text']]\n",
        "reviewHome['text'] = reviewHome['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "tokenizer.fit_on_texts(reviewHome['text'].values)\n",
        "XHG = tokenizer.texts_to_sequences(reviewHome['text'].values)\n",
        "XHG = pad_sequences(XHG)\n",
        "YHG = pd.get_dummies(reviewHome['sentiment']).values\n",
        "X_trainHG, X_testHG, Y_trainHG, Y_testHG = train_test_split(XHG,YHG, test_size = 0.2, random_state = 42)\n",
        "print(X_trainHG.shape,Y_trainHG.shape)\n",
        "print(X_testHG.shape,Y_testHG.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YiXBl3dtpCQ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Band and Credit Union REVIEWS##\n",
        "\n",
        "download_path = '/content/drive/Team Drives/Deep Learning Team Drive/data'\n",
        "reviewBCU = pd.read_pickle(os.path.join(download_path, 'bankandcu_reviews.pickle'))\n",
        "# Suffle review data before any other preprocessing\n",
        "shuffidx = np.random.RandomState(seed=2018).permutation(reviewBCU.shape[0])\n",
        "\n",
        "# Preprocess\n",
        "reviewBCU = reviewBCU.iloc[shuffidx].reset_index(drop=True)\n",
        "reviewBCU = reviewBCU.loc[:, ['stars','text']]\n",
        "reviewBCU = reviewBCU[reviewBCU.stars != 3]\n",
        "reviewBCU.stars.value_counts() # check that there are no \"3\" stars\n",
        "reviewBCU['sentiment']=['pos' if (x>3) else 'neg' for x in reviewBCU['stars']] #add the sentiment column\n",
        "\n",
        "#lowercase/remove punctuations\n",
        "\n",
        "import re\n",
        "\n",
        "reviewBCU['text']= [x.lower() for x in reviewBCU['text']]\n",
        "reviewBCU['text'] = reviewBCU['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "tokenizer.fit_on_texts(reviewBCU['text'].values)\n",
        "XBCU = tokenizer.texts_to_sequences(reviewBCU['text'].values)\n",
        "XBCU = pad_sequences(XBCU)\n",
        "YBCU = pd.get_dummies(reviewBCU['sentiment']).values\n",
        "X_trainBCU, X_testBCU, Y_trainBCU, Y_testBCU = train_test_split(XBCU,YBCU, test_size = 0.2, random_state = 42)\n",
        "print(X_trainBCU.shape,Y_trainBCU.shape)\n",
        "print(X_testBCU.shape,Y_testBCU.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1b4mGbyZSLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ebef484e-783a-4785-f148-f140abb27f3e"
      },
      "cell_type": "code",
      "source": [
        "###GENERAL LSTM###\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 200\n",
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(2000, embed_dim,input_length = XI.shape[1]))\n",
        "model.add(Embedding(2000, embed_dim))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "#model.add(CuDNNLSTM(lstm_out, return_sequences=False, input_shape=(932, 128)))\n",
        "model.add(CuDNNLSTM(lstm_out, return_sequences=False))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, None, 128)         256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_14 (Spatia (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_14 (CuDNNLSTM)    (None, 200)               264000    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 520,402\n",
            "Trainable params: 520,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8pjMDQhY2cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f1a8592e-3446-482e-8740-34e14e09d03e"
      },
      "cell_type": "code",
      "source": [
        "#Fit model (train on Chinese)\n",
        "model.fit(X, Y, validation_split=0.1, epochs=2, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38715 samples, validate on 4302 samples\n",
            "Epoch 1/2\n",
            " - 208s - loss: 0.2907 - acc: 0.8824 - val_loss: 0.2129 - val_acc: 0.9117\n",
            "Epoch 2/2\n",
            " - 207s - loss: 0.1775 - acc: 0.9340 - val_loss: 0.1682 - val_acc: 0.9335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0edfdfe518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "A-H9MRlqY2gr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "173c80c9-df5b-4360-c78a-c8b31f0058c9"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Chinese restaurants\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.13\n",
            "Validation Accuracy: 0.9554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ircLF5C2kI14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aaa79412-b5d2-484a-d949-13db150ec888"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Italy set\n",
        "score,acc = model.evaluate(X_testI, Y_testI, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.15\n",
            "Validation Accuracy: 0.9427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNHEL8ltk2Mc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5b8b5ce-df3d-45e3-e42d-38eef0f2df95"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Mex set\n",
        "score,acc = model.evaluate(X_testM, Y_testM, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.89\n",
            "Validation Accuracy: 0.6981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uE6SlDKHlu4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54d2bab3-6acf-4079-e8a5-4ec422d324e5"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Hair Salon\n",
        "score,acc = model.evaluate(X_testH, Y_testH, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.65\n",
            "Validation Accuracy: 0.7607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bkLDrG75l41M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ffb651e-f602-4484-c2de-266b6c6053e0"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Home Garden\n",
        "score,acc = model.evaluate(X_testHG, Y_testHG, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.03\n",
            "Validation Accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d3on6b7FmVNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31854d7e-9163-443a-e078-ab2d07213436"
      },
      "cell_type": "code",
      "source": [
        "#Test on the BCU\n",
        "score,acc = model.evaluate(X_testBCU, Y_testBCU, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.23\n",
            "Validation Accuracy: 0.5821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7U2T7HgJnM5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e14f9c5a-dfd0-43cd-8a31-0114bfec6524"
      },
      "cell_type": "code",
      "source": [
        "### Try Bidirectional LSTM ###\n",
        "### The following sections ###\n",
        "### were exectued with the following hyper parameters ###\n",
        "\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 200\n",
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(2000, embed_dim))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_out, return_sequences=True)))\n",
        "model.add(Bidirectional(CuDNNLSTM(lstm_out)))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, None, 128)         256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_17 (Spatia (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, None, 400)         528000    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 400)               963200    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 2)                 802       \n",
            "=================================================================\n",
            "Total params: 1,748,002\n",
            "Trainable params: 1,748,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkhXBAKJoWPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7a6cef11-e199-4918-cf57-f9a402bd838e"
      },
      "cell_type": "code",
      "source": [
        "#Fit model (train on Chinese)\n",
        "model.fit(X, Y, validation_split=0.1, epochs=2, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38715 samples, validate on 4302 samples\n",
            "Epoch 1/2\n",
            " - 854s - loss: 0.2791 - acc: 0.8855 - val_loss: 0.2195 - val_acc: 0.9098\n",
            "Epoch 2/2\n",
            " - 854s - loss: 0.1877 - acc: 0.9308 - val_loss: 0.1897 - val_acc: 0.9263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0edf29feb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "uh7MFQTQoWbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "781500b9-649d-4536-afbf-4bbb27b150b8"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Chinese restaurants\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.16\n",
            "Validation Accuracy: 0.9417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iHSjKmWwoWh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "312e6e32-7ea5-4d2a-b925-231597dcd01a"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Italy set\n",
        "score,acc = model.evaluate(X_testI, Y_testI, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.17\n",
            "Validation Accuracy: 0.9343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qzfLlcLUoiF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "101b68cd-3a30-4130-d41c-85f2725bb65d"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Mex set\n",
        "score,acc = model.evaluate(X_testM, Y_testM, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.87\n",
            "Validation Accuracy: 0.6887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6n9nsu5toiLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "188f592e-27f4-42f7-a88e-9bdb5bb97ce9"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Hair Salon\n",
        "score,acc = model.evaluate(X_testH, Y_testH, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.63\n",
            "Validation Accuracy: 0.7570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vA6c5arIoiJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c844de67-922f-4a73-cd1d-76aa8e9b1064"
      },
      "cell_type": "code",
      "source": [
        "#Test on the Home Garden\n",
        "score,acc = model.evaluate(X_testHG, Y_testHG, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.95\n",
            "Validation Accuracy: 0.6632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WX1w_734oWlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "779e048a-c9c9-49e1-d07d-6bc2f65deb15"
      },
      "cell_type": "code",
      "source": [
        "#Test on the BCU\n",
        "score,acc = model.evaluate(X_testBCU, Y_testBCU, verbose = 2, batch_size = batch_size)\n",
        "print(\"Score: %.2f\" % (score))\n",
        "print(\"Validation Accuracy: %.4f\" % (acc))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.19\n",
            "Validation Accuracy: 0.5970\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}